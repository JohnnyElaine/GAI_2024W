{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd2d3a18-bfd2-4a7c-b98d-197ea4fd09de",
   "metadata": {},
   "source": [
    "### 2023.11.30 - Introduction to Transformers |Â Homework 4\n",
    "In this exercise, you will implement key components of Retrieval-Augmented Generation (RAG): Data Ingestion, Retrieval and Augmentation.\n",
    "RAG significantly enhances the capabilities of language models by allowing them to incorporate external knowledge.\n",
    "\n",
    "In case you are interested in diving deeper into RAG, checkout the following resources:\n",
    "- Original Paper on RAG: [Retrieval-Augmented Generation for\n",
    "Knowledge-Intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf)\n",
    "- LamaIndex Tutorial Series: [Building RAG from Scratch (Lower-Level)](https://docs.llamaindex.ai/en/stable/optimizing/building_rag_from_scratch.html)\n",
    "\n",
    "Base your code on the following skeleton code that we provide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e327d59-c60a-4e57-b20d-70de1352b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a32214-f146-4107-bc25-14cfd1a984cb",
   "metadata": {},
   "source": [
    "### Embedding Model\n",
    "The embedding model transforms textual data into a numerical format (embeddings) that can be easily stored and processed.\n",
    "\n",
    "In our exercise we will leverage the free inference API from huggingface as well as an open source model.\n",
    "In order to use this API you need to create an account and obtain an access token under https://huggingface.co/settings/tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c8974e-52bf-4fe2-8196-008a60b1a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"{YOURE ACCESS TOKEN}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8b7474-24b5-4944-96bd-59de4a06ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/BAAI/bge-small-en-v1.5\"\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c60a6-ab8d-469c-a7e3-1516c4758f16",
   "metadata": {},
   "source": [
    "To keep our example simple we will use a small set of predefined, small sentences as our knowledge base. Keep in mind that in real life scenario pre-processing is an important step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb21d03-b1f3-4554-be24-40c23b00b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = [\n",
    "    \"on the 23th december i ate a lovely cheesecake for dinner and a carrot as a breakfast\",\n",
    "    \"the second name of my aunt's second chicken is miranda\",\n",
    "    \"the eiffel tower is located in south tirol.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c453bbee-69bc-4477-b15d-14c00f24c5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Authorization header is correct, but the token seems invalid'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = query({\"inputs\": knowledge_base})\n",
    "embeddings # NOTE: Sometimes the API returns an error, if this is the case, just run this cell again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98541a17-1ed3-4bab-a93f-e6ac8c5f0e22",
   "metadata": {},
   "source": [
    "After encoding our knowledge base into embeddings we need to store them together with the original text, since most embedding models don't provide a decoder element.\n",
    "\n",
    "<b>Task:</b> Create an array of nodes, where each node has the form {\"embd\": THE EMBEDDING, \"text\": THE HUMAN READABLE TEXT}. Each element of the knowledge base should have one node. So your db should look something like [{\"embd\": [0,321, ...], \"text\": \"on the 23th ...\"}, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86c0b24-fcf9-4a03-8f19-b2d72418300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = [] # TODO: DB Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e3741-d6e3-462d-8ac9-c79d3570e6ae",
   "metadata": {},
   "source": [
    "To be able to query our db we need to transform a given prompt into the same vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24df61bf-3c4e-48c9-be32-16b8e216c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the second name of my aunt's second chicken?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b27737d-d862-4b01-a1a3-e922c8b2fdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Authorization header is correct, but the token seems invalid'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embd = query({\"inputs\": prompt})\n",
    "prompt_embd # NOTE: Sometimes the API returns an error, if this is the case, just run this cell again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091540f-dfd0-476d-9b44-7a2f30b95a48",
   "metadata": {},
   "source": [
    "<b>Task:</b> Implement a function named calculate_similarity which takes two arguments, vec1 and vec2. These arguments represent text embeddings that should be semantically compared. The function should return a single similarity value between 0 and 1, where 1 indicates an identical vector and 0 orthogonal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d67191f-ab2c-48cf-9fe7-43cdcf9ea6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "    vec1 (list or array): The first vector.\n",
    "    vec2 (list or array): The second vector.\n",
    "\n",
    "    Returns:\n",
    "    float: A similarity score between 0 and 1, where 1 means identical and 0 means orthogonal.\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6eb6f-2a28-4290-ac4d-c9dc0b1ec005",
   "metadata": {},
   "source": [
    "<b>Task:</b> Calculate the cosine similarity between a given prompt embedding and each embedding in your database (db).\n",
    "Identify the database entry (node) that has the highest similarity to the prompt and retrieve the text associated with this most similar node as your augmentation data. (_hint:_ you might want to use np.argmax on an array of similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0483a28d-de95-4b87-afc0-124af3247c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement similarity search\n",
    "augmentation_data = \"\" # text of the most similar node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8217bab-cf33-4da8-9879-f8e2d8cf20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented_prompt(prompt, augmentation):\n",
    "    return f\"\"\"\n",
    "Context information: \"{augmentation}\".\n",
    "Given the context information and no prior knowledge, answer the query.\n",
    "Query: {prompt}\n",
    "Answer: \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2059e4d-50e3-471b-a55d-fb028085faab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nContext information: \"\".\\nGiven the context information and no prior knowledge, answer the query.\\nQuery: What is the second name of my aunt\\'s second chicken?\\nAnswer: '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Expected Output:\n",
    "'\\nContext information: \"the second name of my aunt's second chicken is miranda\".\\nGiven the context information and no prior knowledge, answer the query.\\nQuery: What is the second name of my aunt's second chicken?\\nAnswer: '\n",
    "\"\"\"\n",
    "\n",
    "augmented_prompt = get_augmented_prompt(prompt, augmentation_data)\n",
    "augmented_prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
