{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98989f75-7aa1-4366-bb17-012bce0f52b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa2936432f9a56192f24fd92409cbc8a",
     "grade": false,
     "grade_id": "cell-51c85f1a1a5c819b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2024.10.24 - Generative AI | Homework 1 Assignment\n",
    "In this exercise, you will implement a static (i.e. not learned) Embedding Layer and the Positional Encoding Layer.\\\n",
    "Base your code on the skeleton code that we provide.\n",
    "\n",
    "Passages, where you should add your implementation, are marked with\n",
    "\n",
    "\\# YOUR CODE HERE</br>\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "Each of the two tasks has a maximum of 0,5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f196f8-9bf3-4b04-8de0-8434aa4287ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2dd394926dec3edd421bd6b182d3818",
     "grade": false,
     "grade_id": "cell-45fcba4fa2261717",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 1 -  Embedding Layer (0,5p):\n",
    "Implement a static embedding layer. This layer should be able to:\n",
    "- Look up and return embeddings for a given list of token IDs.\n",
    "- Handle potential out-of-bounds errors when looking up embeddings."
   ]
  },
  {
   "cell_type": "code",
   "id": "b35a41da-369a-4bd3-9e16-5c00e332530b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88958ffbefbb56a9ba05fdb4ffba5d68",
     "grade": false,
     "grade_id": "cell-32e4527c633688cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T02:12:50.460965Z",
     "start_time": "2024-10-28T02:12:50.457553Z"
    }
   },
   "source": [
    "import math\n",
    "from typing import List\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "id": "3f71920c-054f-4ec7-a8c2-38cc7cc904ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acaffb3625dc6d6ef3ab89ddea3e17a6",
     "grade": false,
     "grade_id": "cell-decd6911b2b32cab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "class Embedding:\n    def __init__(self, n_embd: int, d_embd: int):\n        \"\"\"\n        A simple embedding layer that maps token indices to dense vectors.\n\n        Args:\n            n_embd (int): Number of embeddings (vocabulary size)\n            d_embd (int): Dimensionality of each embedding vector\n        \"\"\"\n        torch.manual_seed(42)\n        self.lookup = torch.randn(n_embd, d_embd)\n\n    def forward(self, input: Tensor) -> Tensor:\n        \"\"\"\n        Maps token indices to their corresponding embedding vectors.\n        \n        This operation is essentially a lookup or indexing operation where each input token ID\n        is replaced by its corresponding vector from the embedding table.\n        \n        Args:\n            input (Tensor): An unidimensional tensor of token indices each value should be in range [0, n_embd-1]\n        \n        Returns:\n            Tensor: The embedding vectors for each input token\n                    Shape: (sequence_length, d_embd)\n        \n        Raises:\n            ValueError: If any input index is out of bounds of the embedding table\n        \"\"\"\n        # YOUR CODE HERE\n        raise NotImplementedError()\n\n    def __call__(self, input: Tensor) -> Tensor:\n        # This function lets you call a class instance as a function e.g. Embedding(n_embd, d_emdb)(x)\n        # https://docs.python.org/3/reference/datamodel.html#object.__call__\n        return self.forward(input)",
    "ExecuteTime": {
     "end_time": "2024-10-28T02:11:07.229555Z",
     "start_time": "2024-10-28T02:11:07.226245Z"
    }
   },
   "source": [
    "class Embedding:\n",
    "    def __init__(self, n_embd: int, d_embd: int):\n",
    "        \"\"\"\n",
    "        A simple embedding layer that maps token indices to dense vectors.\n",
    "\n",
    "        Args:\n",
    "            n_embd (int): Number of embeddings (vocabulary size)\n",
    "            d_embd (int): Dimensionality of each embedding vector\n",
    "        \"\"\"\n",
    "        torch.manual_seed(42)\n",
    "        self.lookup = torch.randn(n_embd, d_embd)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Maps token indices to their corresponding embedding vectors.\n",
    "        \n",
    "        This operation is essentially a lookup or indexing operation where each input token ID\n",
    "        is replaced by its corresponding vector from the embedding table.\n",
    "        \n",
    "        Args:\n",
    "            input (Tensor): An unidimensional tensor of token indices each value should be in range [0, n_embd-1]\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The embedding vectors for each input token\n",
    "                    Shape: (sequence_length, d_embd)\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If any input index is out of bounds of the embedding table\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return self.lookup[input]\n",
    "\n",
    "    def __call__(self, input: Tensor) -> Tensor:\n",
    "        # This function lets you call a class instance as a function e.g. Embedding(n_embd, d_emdb)(x)\n",
    "        # https://docs.python.org/3/reference/datamodel.html#object.__call__\n",
    "        return self.forward(input)"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "id": "eaa082cd-9022-40b4-8b25-626fe87f832a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0592c4c44a88a2a80ac05e13a7408db2",
     "grade": false,
     "grade_id": "cell-59f5f669b043a9e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T02:11:07.232827Z",
     "start_time": "2024-10-28T02:11:07.229555Z"
    }
   },
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, vocab: List[str]):\n",
    "        self.vocab = vocab\n",
    "        self.token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "        self.idx2token = {idx: token for idx, token in enumerate(vocab)}\n",
    "\n",
    "    def parse(self, input: str) -> List[str]:\n",
    "        \"\"\"Tokenkize a string to a list of whitespace-separated substrings.\"\"\"\n",
    "        return input.split(' ')\n",
    "\n",
    "    def encode(self, tokens: List[str]) -> List[int]:\n",
    "        \"\"\"Encode a list of tokens into their corresponding indices.\"\"\"\n",
    "        return [self.token2idx.get(token, self.token2idx.get('<unk>', None)) for token in tokens]\n",
    "\n",
    "    def decode(self, indices: List[int]) -> str:\n",
    "        \"\"\"Decode a list of indices back into a string.\"\"\"\n",
    "        return ' '.join([self.idx2token.get(idx, '<unk>') for idx in indices])    "
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "id": "da3efc2e-3aa7-40c6-ae6f-289e7babee82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11a2094d5bbe473f620f1826067d5968",
     "grade": false,
     "grade_id": "cell-e0b6f10f7837389e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T02:11:07.235486Z",
     "start_time": "2024-10-28T02:11:07.232827Z"
    }
   },
   "source": [
    "def assert_raises(fn, *args, **kwargs):\n",
    "    # A helper function to assert a function call throws an exception\n",
    "    try:\n",
    "        fn(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(f\"✅ Expected error occurred: {type(e).__name__} - {e}\")\n",
    "        return\n",
    "    raise AssertionError(\"Expected error did not occur\")"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "id": "b758fc81-041b-4288-b43d-cc920cd89dbd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19ffee60d98fbfcaa13653eee51d0389",
     "grade": false,
     "grade_id": "cell-19cddb620d50521c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Task 1 - Verification\n",
    "\n",
    "Use the cell below to test your implementation. You can expect to gain the full score on this exercise if assertions pass."
   ]
  },
  {
   "cell_type": "code",
   "id": "3e598db2-08d4-4458-ab54-5351f480af5b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8494a599c1f19af358e5c17baaed4a2",
     "grade": true,
     "grade_id": "cell-9684ddb78b03ecf3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T02:11:07.242347Z",
     "start_time": "2024-10-28T02:11:07.236491Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Expected Output:\n",
    "\n",
    "============ Embedding Layer\n",
    "input (torch.Size([8])):\n",
    "tensor([ 1, 13,  2,  5,  6,  1, 14,  3])\n",
    "\n",
    "embedding_layer result (torch.Size([8, 3])):\n",
    "tensor([[-2.1055,  0.6784, -1.2345],\n",
    "        [-1.2862, -1.4032,  0.0360],\n",
    "        [-0.0431, -1.6047, -0.7521],\n",
    "        [ 0.7624,  1.6423, -0.1596],\n",
    "        [-0.4974,  0.4396, -0.7581],\n",
    "        [-2.1055,  0.6784, -1.2345],\n",
    "        [-0.0635,  0.6756, -0.0978],\n",
    "        [ 1.6487, -0.3925, -1.4036]])\n",
    "Expected error occurred: ValueError - Input tensor contains invalid indices for lookup table.\n",
    "\"\"\"\n",
    "print(\"============ Embedding Layer\")\n",
    "\n",
    "vocab = [\"<unk>\", \"the\", \"dog\", \"cat\", \"runs\", \"jumps\", \"over\", \"and\",\n",
    "         \"sleeps\", \"eats\", \"food\", \"fast\", \"slow\", \"big\", \"small\"]\n",
    "tokenizer = Tokenizer(vocab)\n",
    "n_embd = len(vocab)\n",
    "d_embd = 3\n",
    "embedding_layer = Embedding(n_embd, d_embd)\n",
    "\n",
    "input_sequence = \"the big dog jumps over the small cat\"\n",
    "input_id_sequence = tokenizer.encode(tokenizer.parse(input_sequence))\n",
    "input_tensor = torch.tensor(input_id_sequence)\n",
    "\n",
    "embeddings = embedding_layer(input_tensor)\n",
    "\n",
    "print(f\"input ({input_tensor.size()}):\\n{input_tensor}\\n\")\n",
    "print(f\"embedding_layer result ({embeddings.size()}):\\n{embeddings}\")\n",
    "\n",
    "# Assure layer throws exception on invalid index\n",
    "assert_raises(embedding_layer, torch.tensor([n_embd]))\n",
    "\n",
    "# Assert embeddings are as expected\n",
    "expected = torch.tensor([[-2.1055,  0.6784, -1.2345],\n",
    "        [-1.2862, -1.4032,  0.0360],\n",
    "        [-0.0431, -1.6047, -0.7521],\n",
    "        [ 0.7624,  1.6423, -0.1596],\n",
    "        [-0.4974,  0.4396, -0.7581],\n",
    "        [-2.1055,  0.6784, -1.2345],\n",
    "        [-0.0635,  0.6756, -0.0978],\n",
    "        [ 1.6487, -0.3925, -1.4036]], dtype=embeddings.dtype)\n",
    "assert torch.allclose(expected, embeddings, atol=1e-4)\n",
    "\n",
    "print(\"\\nLooks good ✅!\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Embedding Layer\n",
      "input (torch.Size([8])):\n",
      "tensor([ 1, 13,  2,  5,  6,  1, 14,  3])\n",
      "\n",
      "embedding_layer result (torch.Size([8, 3])):\n",
      "tensor([[-2.1055,  0.6784, -1.2345],\n",
      "        [-1.2862, -1.4032,  0.0360],\n",
      "        [-0.0431, -1.6047, -0.7521],\n",
      "        [ 0.7624,  1.6423, -0.1596],\n",
      "        [-0.4974,  0.4396, -0.7581],\n",
      "        [-2.1055,  0.6784, -1.2345],\n",
      "        [-0.0635,  0.6756, -0.0978],\n",
      "        [ 1.6487, -0.3925, -1.4036]])\n",
      "✅ Expected error occurred: IndexError - index 15 is out of bounds for dimension 0 with size 15\n",
      "\n",
      "Looks good ✅!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "id": "d02d0bbb-32ef-46d4-997c-d1e5021efe39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7951fe4e60edeac7c158e7762a5db183",
     "grade": false,
     "grade_id": "cell-6dee57afcbee07c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 2 - Positional Encoding (0,5p):\n",
    "Implement the sinusoidal positional encoding as described in the lecture.\n",
    "The positional encoding should:\n",
    "- Generate position encodings for sequences up to a maximum length\n",
    "- Use sine and cosine functions of different frequencies\n",
    "- Have the same dimensionality as the embeddings\n",
    "- Be added to the embeddings to create position-aware representations\n",
    "\n",
    "The positional encoding can be implemented mainly in two ways:\n",
    "\n",
    "1. Loop-based approach:\n",
    "   - Loop through each position and dimension\n",
    "   - For each position pos and dimension i:\n",
    "     * Even dimensions use sine: PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "     * Odd dimensions use cosine: PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "2. Vectorized approach (more efficient):\n",
    "   - Create position vector: [0, 1, 2, ...] and reshape to (max_len, 1)\n",
    "   - Create division terms for even dimensions: 10000^(2i/d_model)\n",
    "   - Use broadcasting to compute all positions at once:\n",
    "     position_vector / div_terms -> gives all frequency terms\n",
    "   - Assign to even/odd indices using stride slicing (:, 0::2 and :, 1::2)"
   ]
  },
  {
   "cell_type": "code",
   "id": "afa2558e-54c9-4a6b-b8f8-88cb1fea3046",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "412c6310579074d03975673e80f9e0a7",
     "grade": false,
     "grade_id": "cell-970fd8d016a333c0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "class PositionalEncoding:\n    def __init__(self, d_model: int, max_len: int = 10):\n        \"\"\"\n        Initialize the positional encoding matrix.\n        The matrix should encode position information using sine and cosine functions.\n        \"\"\"\n        \n        self.pe = torch.zeros(max_len, d_model)        \n        # IMPLEMENT THE POSITIONAL ENCODING HERE\n        # Use the formula from the \"Attention Is All You Need\" paper:\n        # PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n        # PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n        #\n        # Important: Ensure that the final position encoding matrix is assigned to self.pe\n\n        # YOUR CODE HERE\n        raise NotImplementedError()\n        \n        \n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"\n        Add positional encodings to the input embeddings.\n        \n        Args:\n            x: Input embeddings tensor of shape (sequence_length, d_model)\n        \n        Returns:\n            Input embeddings with positional encoding added\n        \"\"\"\n        # Get the length of the input sequence\n        seq_len = x.size(0)\n        \n        # Add positional encodings to the input embeddings\n        # We only use as many positions as we have tokens in the sequence\n        return x + self.pe[:seq_len, :]\n\n    def __call__(self, x: Tensor) -> Tensor:\n        return self.forward(x)",
    "ExecuteTime": {
     "end_time": "2024-10-28T02:11:07.245888Z",
     "start_time": "2024-10-28T02:11:07.242347Z"
    }
   },
   "source": [
    "class PositionalEncoding:\n",
    "    def __init__(self, d_model: int, max_len: int = 10):\n",
    "        \"\"\"\n",
    "        Initialize the positional encoding matrix.\n",
    "        The matrix should encode position information using sine and cosine functions.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.pe = torch.zeros(max_len, d_model)        \n",
    "        # IMPLEMENT THE POSITIONAL ENCODING HERE\n",
    "        # Use the formula from the \"Attention Is All You Need\" paper:\n",
    "        # PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "        # PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "        #\n",
    "        # Important: Ensure that the final position encoding matrix is assigned to self.pe\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        position_vector = torch.arange(max_len, dtype=torch.float).reshape(max_len, 1)\n",
    "        \n",
    "        # Create division terms for even dimensions: 10000^(2i/d_model)\n",
    "        div_terms = 10000 ** (torch.arange(0, d_model, 2, dtype=torch.float) / d_model)\n",
    "        \n",
    "        # Compute all frequency terms using broadcasting\n",
    "        # This gives us the frequency for each position and dimension\n",
    "        freq_terms = position_vector / div_terms\n",
    "        \n",
    "        # Assign to even/odd indices using stride slicing\n",
    "        self.pe = torch.zeros(max_len, d_model)\n",
    "        self.pe[:, 0::2] = torch.sin(freq_terms)  # even indices\n",
    "        self.pe[:, 1::2] = torch.cos(freq_terms)  # odd indices\n",
    "        \n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Add positional encodings to the input embeddings.\n",
    "        \n",
    "        Args:\n",
    "            x: Input embeddings tensor of shape (sequence_length, d_model)\n",
    "        \n",
    "        Returns:\n",
    "            Input embeddings with positional encoding added\n",
    "        \"\"\"\n",
    "        # Get the length of the input sequence\n",
    "        seq_len = x.size(0)\n",
    "        \n",
    "        # Add positional encodings to the input embeddings\n",
    "        # We only use as many positions as we have tokens in the sequence\n",
    "        return x + self.pe[:seq_len, :]\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        return self.forward(x)"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "id": "d2d956a6-8aba-4614-8f7b-7d7d9fecefc3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1970dbe2e2a0713b493c1206a0e6305c",
     "grade": false,
     "grade_id": "cell-fb4eb335790ed0d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Look at the plot below - it should look similar to what you have seen on the slide."
   ]
  },
  {
   "cell_type": "code",
   "id": "a39506cd-5ae6-4bcb-8f9e-e0dc24b33ae4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56c5f8957ede6a28d42cd0444d8ebf47",
     "grade": false,
     "grade_id": "cell-133123d8afe94eea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T02:11:07.257214Z",
     "start_time": "2024-10-28T02:11:07.245888Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seq_length = 100\n",
    "d_model = 100\n",
    "x = torch.ones(seq_length, d_model)\n",
    "\n",
    "pe = PositionalEncoding(d_model, seq_length)\n",
    "encoded = pe(x)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(encoded.detach().numpy(), cmap='viridis', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Embedding Dimension')\n",
    "plt.ylabel('Sequence Position')\n",
    "plt.title('Positional Encoding Pattern')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[102], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Plot\u001B[39;00m\n\u001B[0;32m     11\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m---> 12\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mencoded\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mviridis\u001B[39m\u001B[38;5;124m'\u001B[39m, aspect\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m plt\u001B[38;5;241m.\u001B[39mcolorbar()\n\u001B[0;32m     14\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmbedding Dimension\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Numpy is not available"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "id": "f4ff30ee-6247-44b2-aea6-9710026a6279",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ac8bfe508534f652b57d2b58a8dbd64",
     "grade": false,
     "grade_id": "cell-54b720ab567cf90c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Task 2 - Verification\n",
    "\n",
    "Use the cell below to test your implementation. You can expect to gain the full score on this exercise if assertions pass."
   ]
  },
  {
   "cell_type": "code",
   "id": "278393c1-1a87-4da8-9cee-82512c3ad54c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fc215fe640bf3c53dcd96c099e98996",
     "grade": true,
     "grade_id": "cell-4595f3003b9ce495",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-28T02:11:07.257214Z",
     "start_time": "2024-10-28T02:11:07.257214Z"
    }
   },
   "source": [
    "print(\"============ Positional Encoding\")\n",
    "d_model, max_len = 4, 3\n",
    "pe = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "##### TEST CASE 1\n",
    "print(\"Validating shape of result ...\")\n",
    "assert pe.pe.shape == (max_len, d_model), f\"Expected shape ({max_len}, {d_model}), got {pe.pe.shape}\"\n",
    "\n",
    "##### TEST CASE 2\n",
    "print(\"Validating known values for small input ...\")\n",
    "expected_pe = torch.tensor([\n",
    "    [ 0.0000,  1.0000,  0.0000,  1.0000],\n",
    "    [ 0.8415,  0.5403,  0.0100,  1.0000],\n",
    "    [ 0.9093, -0.4161,  0.0200,  0.9998]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "assert torch.allclose(pe.pe, expected_pe, atol=1e-4), \\\n",
    "    f\"Expected:\\n{expected_pe}\\nGot:\\n{pe.pe}\"\n",
    "\n",
    "##### TEST CASE 3\n",
    "print(\"Validating forward pass with embeddings ...\")\n",
    "embeddings = torch.ones(2, d_model)\n",
    "output = pe(embeddings)\n",
    "expected_output = embeddings + expected_pe[:2]  # Only first 2 positions\n",
    "assert torch.allclose(output, expected_output, atol=1e-4), \\\n",
    "    f\"Forward pass failed. Expected:\\n{expected_output}\\nGot:\\n{output}\"\n",
    "\n",
    "##### TEST CASE 4\n",
    "print(\"Validating properties that should hold for any valid implementation ...\")\n",
    "pe_large = PositionalEncoding(d_model=8, max_len=5)\n",
    "\n",
    "# Even indices should use sine, odd indices should use cosine\n",
    "# Test first position (pos=0)\n",
    "assert torch.allclose(pe_large.pe[0, 0::2], torch.zeros(4), atol=1e-6), \\\n",
    "    \"First position should have zeros for sine components\"\n",
    "assert torch.allclose(pe_large.pe[0, 1::2], torch.ones(4), atol=1e-6), \\\n",
    "    \"First position should have ones for cosine components\"\n",
    "\n",
    "# Test that frequencies decrease with dimension\n",
    "# Compare amplitudes of changes between positions for different dimensions\n",
    "changes = torch.abs(pe_large.pe[1:] - pe_large.pe[:-1])  # Position-wise changes\n",
    "for i in range(0, d_model-2, 2):\n",
    "    assert torch.mean(changes[:, i]) > torch.mean(changes[:, i+2]), \\\n",
    "        f\"Frequency should decrease with dimension. Error at dimension {i}\"\n",
    "\n",
    "print(\"\\nLooks good ✅!\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
